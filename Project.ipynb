{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Module 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "#using Plotly\n",
    "using QuadGK\n",
    "using Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_data()\n",
    "    # SNname z sigma_z m_x_peak sigma_x_peak A_x K_bx m_b_peak m_b_eff sigma_m_b_eff\n",
    "    latex = \"\"\"\n",
    "    1992bi   0.458   0.001   22.12   0.10   0.03   -0.72   22.81   23.11   0.46 \\\\\n",
    "    1994F    0.354   0.001   22.08   0.10   0.11   -0.58   22.55   22.38   0.33 \\\\\n",
    "    1994G    0.425   0.001   21.52   0.21   0.03   -0.68   22.17   22.13   0.49 \\\\\n",
    "    1994H    0.374   0.001   21.28   0.06   0.10   -0.61   21.79   21.72   0.22 \\\\\n",
    "    1994al   0.420   0.001   22.37   0.06   0.42   -0.68   22.63   22.55   0.25 \\\\\n",
    "    1994am   0.372   0.001   21.82   0.07   0.10   -0.61   22.32   22.26   0.20 \\\\\n",
    "    1994an   0.378   0.001   22.14   0.08   0.21   -0.62   22.55   22.58   0.37 \\\\\n",
    "    1995aq   0.453   0.001   22.60   0.07   0.07   -0.71   23.24   23.17   0.25 \\\\\n",
    "    1995ar   0.465   0.005   22.71   0.04   0.07   -0.71   23.35   23.33   0.30 \\\\\n",
    "    1995as   0.498   0.001   23.02   0.07   0.07   -0.71   23.66   23.71   0.25 \\\\\n",
    "    1995at   0.655   0.001   22.62   0.03   0.07   -0.66   23.21   23.27   0.21 \\\\\n",
    "    1995aw   0.400   0.030   21.75   0.03   0.12   -0.65   22.27   22.36   0.19 \\\\\n",
    "    1995ax   0.615   0.001   22.53   0.07   0.11   -0.67   23.10   23.19   0.25 \\\\\n",
    "    1995ay   0.480   0.001   22.64   0.04   0.35   -0.72   23.00   22.96   0.24 \\\\\n",
    "    1995az   0.450   0.001   22.44   0.07   0.61   -0.71   22.53   22.51   0.23 \\\\\n",
    "    1995ba   0.388   0.001   22.08   0.04   0.06   -0.63   22.66   22.65   0.20 \\\\\n",
    "    1996cf   0.570   0.010   22.70   0.03   0.13   -0.68   23.25   23.27   0.22 \\\\\n",
    "    1996cg   0.490   0.010   22.46   0.03   0.11   -0.72   23.06   23.10   0.20 \\\\\n",
    "    1996ci   0.495   0.001   22.19   0.03   0.09   -0.71   22.82   22.83   0.19 \\\\\n",
    "    1996ck   0.656   0.001   23.08   0.07   0.13   -0.66   23.62   23.57   0.28 \\\\\n",
    "    1996cl   0.828   0.001   23.53   0.10   0.18   -1.22   24.58   24.65   0.54 \\\\\n",
    "    1996cm   0.450   0.010   22.66   0.07   0.15   -0.71   23.22   23.17   0.23 \\\\\n",
    "    1996cn   0.430   0.010   22.58   0.03   0.08   -0.69   23.19   23.13   0.22 \\\\\n",
    "    1997F    0.580   0.001   22.90   0.06   0.13   -0.68   23.45   23.46   0.23 \\\\\n",
    "    1997G    0.763   0.001   23.56   0.41   0.20   -1.13   24.49   24.47   0.53 \\\\\n",
    "    1997H    0.526   0.001   22.68   0.05   0.16   -0.70   23.21   23.15   0.20 \\\\\n",
    "    1997I    0.172   0.001   20.04   0.02   0.16   -0.33   20.20   20.17   0.18 \\\\\n",
    "    1997J    0.619   0.001   23.25   0.08   0.13   -0.67   23.80   23.80   0.28 \\\\\n",
    "    1997K    0.592   0.001   23.73   0.10   0.07   -0.67   24.33   24.42   0.37 \\\\\n",
    "    1997L    0.550   0.010   22.93   0.05   0.08   -0.69   23.53   23.51   0.25 \\\\\n",
    "    1997N    0.180   0.001   20.19   0.01   0.10   -0.34   20.42   20.43   0.17 \\\\\n",
    "    1997O    0.374   0.001   22.97   0.07   0.09   -0.61   23.50   23.52   0.24 \\\\\n",
    "    1997P    0.472   0.001   22.52   0.04   0.10   -0.72   23.14   23.11   0.19 \\\\\n",
    "    1997Q    0.430   0.010   22.01   0.03   0.09   -0.69   22.60   22.57   0.18 \\\\\n",
    "    1997R    0.657   0.001   23.28   0.05   0.11   -0.66   23.83   23.83   0.23 \\\\\n",
    "    1997S    0.612   0.001   23.03   0.05   0.11   -0.67   23.59   23.69   0.21 \\\\\n",
    "    1997ac   0.320   0.010   21.38   0.03   0.09   -0.55   21.83   21.86   0.18 \\\\\n",
    "    1997af   0.579   0.001   22.96   0.07   0.09   -0.68   23.54   23.48   0.22 \\\\\n",
    "    1997ai   0.450   0.010   22.25   0.05   0.14   -0.71   22.81   22.83   0.30 \\\\\n",
    "    1997aj   0.581   0.001   22.55   0.06   0.11   -0.68   23.12   23.09   0.22 \\\\\n",
    "    1997am   0.416   0.001   21.97   0.03   0.11   -0.67   22.52   22.57   0.20 \\\\\n",
    "    1997ap   0.830   0.010   23.20   0.07   0.13   -1.23   24.30   24.32   0.22 \\\\\n",
    "    1990O    0.030   0.002   16.62   0.03   0.39  -0.00   16.23   16.26   0.20  \\\\\n",
    "    1990af   0.050   0.002   17.92   0.01   0.16   0.01   17.75   17.63   0.18 \\\\\n",
    "    1992P    0.026   0.002   16.13   0.03   0.12  -0.01   16.02   16.08   0.24 \\\\\n",
    "    1992ae   0.075   0.002   18.61   0.12   0.15   0.03   18.43   18.43   0.20 \\\\\n",
    "    1992ag   0.026   0.002   16.59   0.04   0.38  -0.01   16.22   16.28   0.20 \\\\\n",
    "    1992al   0.014   0.002   14.60   0.01   0.13  -0.01   14.48   14.47   0.23 \\\\\n",
    "    1992aq   0.101   0.002   19.29   0.12   0.05   0.05   19.19   19.16   0.23 \\\\\n",
    "    1992bc   0.020   0.002   15.20   0.01   0.07  -0.01   15.13   15.18   0.20 \\\\\n",
    "    1992bg   0.036   0.002   17.41   0.07   0.77   0.00   16.63   16.66   0.21 \\\\\n",
    "    1992bh   0.045   0.002   17.67   0.04   0.10   0.01   17.56   17.61   0.19 \\\\\n",
    "    1992bl   0.043   0.002   17.31   0.07   0.04   0.01   17.26   17.19   0.18 \\\\\n",
    "    1992bo   0.018   0.002   15.85   0.02   0.11  -0.01   15.75   15.61   0.21 \\\\\n",
    "    1992bp   0.079   0.002   18.55   0.02   0.21   0.04   18.30   18.27   0.18 \\\\\n",
    "    1992br   0.088   0.002   19.71   0.07   0.12   0.04   19.54   19.28   0.18 \\\\\n",
    "    1992bs   0.063   0.002   18.36   0.05   0.09   0.03   18.24   18.24   0.18 \\\\\n",
    "    1993B    0.071   0.002   18.68   0.08   0.31   0.03   18.34   18.33   0.20 \\\\\n",
    "    1993O    0.052   0.002   17.83   0.01   0.25   0.01   17.58   17.54   0.18 \\\\\n",
    "    1993ag   0.050   0.002   18.29   0.02   0.56   0.01   17.71   17.69   0.20 \\\\\n",
    "    \"\"\"\n",
    "    lines = split(latex, '\\n')\n",
    "    lines = filter(x->length(x)>0, lines)\n",
    "    \n",
    "    z = zeros(length(lines))\n",
    "    sigma_z = zeros(length(lines))\n",
    "    m_x_peak = zeros(length(lines))\n",
    "    sigma_x_peak = zeros(length(lines))\n",
    "    A_x = zeros(length(lines))\n",
    "    K_bx = zeros(length(lines))\n",
    "    m_b_peak = zeros(length(lines))\n",
    "    m_b_eff = zeros(length(lines))\n",
    "    sigma_m_b_eff = zeros(length(lines))\n",
    "    names = []\n",
    "    \n",
    "    for (i,line) in enumerate(lines)\n",
    "        words = split(line, r\"\\s+\")\n",
    "        push!(names, words[1])\n",
    "        z[i] = parse(Float64, words[2])\n",
    "        sigma_z[i] = parse(Float64, words[3])\n",
    "        m_x_peak[i] = parse(Float64, words[4])\n",
    "        sigma_x_peak[i] = parse(Float64, words[5])\n",
    "        A_x[i] = parse(Float64, words[6])\n",
    "        K_bx[i] = parse(Float64, words[7])\n",
    "        m_b_peak[i] = parse(Float64, words[8])\n",
    "        m_b_eff[i] = parse(Float64, words[9])\n",
    "        sigma_m_b_eff[i] = parse(Float64, words[10])\n",
    "    end\n",
    "    return names, z, sigma_z, m_x_peak, sigma_x_peak, A_x, K_bx, m_b_peak, m_b_eff, sigma_m_b_eff\n",
    "end;\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name, z, m, merr = get_data()[1],get_data()[2],get_data()[9],get_data()[10];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data set looks just as it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(z, m, yerr=merr, seriestype=:scatter, label=\"\", xlabel=\"Redshift z\", ylabel=\"m_B\",\n",
    "title=\"Perlmutter+99 Supernovae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function given from Perlmutter99, it calculates all the needed values for calculating the luminosity distance which is needed for the fit-function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These functions are taken from astropy.cosmology, specialized for\n",
    "# the FlatLambdaCDM model.\n",
    "#\n",
    "\n",
    "# A minimal Flat Lambda CDM model\n",
    "mutable struct LCDM\n",
    "    Om0::Float64\n",
    "    Ode0::Float64\n",
    "    hubble_distance::Float64\n",
    "end\n",
    "\n",
    "#\n",
    "function luminosity_distance(cosmology, z)\n",
    "    return (1. + z) * comoving_transverse_distance(cosmology, z)\n",
    "end\n",
    "function comoving_transverse_distance(cosmology, z)\n",
    "    return comoving_transverse_distance_z1z2(cosmology, 0., z)\n",
    "end\n",
    "function comoving_transverse_distance_z1z2(cosmology, z1, z2)\n",
    "    # HERE we're assuming Ok0=0\n",
    "    # (Omega curvature; the effective curvature density/critical density at z=0)\n",
    "    return comoving_distance_z1z2(cosmology, z1, z2)\n",
    "end\n",
    "\n",
    "function comoving_distance_z1z2(cosmology, z1, z2)\n",
    "    #hypergeometric_comoving_distance_z1z2(cosmology, z1, z2)\n",
    "    integral_comoving_distance_z1z2(cosmology, z1, z2)\n",
    "end\n",
    "\n",
    "function integral_comoving_distance_z1z2(cosmology, z1, z2)\n",
    "    function flcdm_inv_efunc_norel(z)\n",
    "        Om0 = cosmology.Om0\n",
    "        Ode0 = cosmology.Ode0\n",
    "        return ((1. + z)^3 * Om0 + Ode0) ^ -0.5\n",
    "    end\n",
    "    # HERE we turn off relativistic species (Tcmb=0)\n",
    "    (integral,error) = quadgk(flcdm_inv_efunc_norel, z1, z2)\n",
    "    return cosmology.hubble_distance * integral\n",
    "end\n",
    "\n",
    "function hypergeometric_comoving_distance_z1z2(cosmology, z1, z2)\n",
    "    # def _hypergeometric_comoving_distance_z1z2(self, z1, z2):\n",
    "    s = ((1 - cosmology.Om0) / cosmology.Om0) ^ (1. / 3)\n",
    "    # Use np.sqrt here to handle negative s (Om0>1).\n",
    "    prefactor = cosmology.hubble_distance / sqrt(s * cosmology.Om0)\n",
    "    return prefactor * (T_hypergeometric(s / (1 + z1)) -\n",
    "                        T_hypergeometric(s / (1 + z2)))\n",
    "end\n",
    "function T_hypergeometric(x)\n",
    "    #from scipy.special import hyp2f1\n",
    "    return 2 * sqrt(x) * Nemo.hyp2f1(1. / 6, 1. / 2, 7. / 6, -x^3)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "universe = LCDM(0.25, 0.75, 60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perlmutter+ define D_L = H_0 d_L; you could drop the factor of hubble_distance\n",
    "# from luminosity_distance here if you wanted.  It will all just get folded into the\n",
    "# M_B offset.\n",
    "function distance_modulus(universe, z)\n",
    "    5. * log10.(luminosity_distance(universe, z) / 10.) #WHY / 10??\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I get suspicious. The variable $\\Omega_M$ just goes into DL in a logarithmic way. Therefore, a change in $\\Omega_M$ has little influence on the outcome (edit: big influence for argument < 1 maybe?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(z, m, yerr=merr, seriestype=:scatter, label=\"\", xlabel=\"Redshift z\", ylabel=\"m\",\n",
    "title=\"Perlmutter+99 Supernovae\")\n",
    "zgrid = 0.01:0.01:1.\n",
    "DL = map(z->distance_modulus(universe, z), zgrid)\n",
    "\n",
    "DLx = map(z->distance_modulus(universe, z), z)\n",
    "offset = median(m - DLx)\n",
    "plot!(zgrid, DL .+ offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mb, Omega_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Okay so that's all we are given. Now I want to do a MCMC with a fgbg in before to get rid of the outliners. So I start with implementing the fbgb model. This is a try where my fitting parameters are $M_b$ and $\\Omega_M$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function fgbg_line_log_likelihood(z, m, merr, Mb, Om, pbad, Y, V) # dL(z, Om, Olam)\n",
    "    # If the \"pbad\" parameter goes outside the range 0 to 1, the prior is zero, so bail out.\n",
    "    if (pbad < 0) || (pbad > 1)\n",
    "        return -Inf\n",
    "    end\n",
    "    # If the \"V\" parameter goes negative, the prior is zero; bail out.\n",
    "    if (V < 0)\n",
    "        return -Inf\n",
    "    end\n",
    "    Olam = 1-Om\n",
    "    uni = LCDM(Om, Olam, 60.)\n",
    "    zgrid = 0.:0.01:1.\n",
    "    dL = map(z->distance_modulus(uni, z), z) #60-elem array\n",
    "    # Note -- don't work in log space here, and do include the 1/(sqrt(2*pi)*sigma) term.\n",
    "    p_fg = @. 1. / (sqrt(2. *pi) * merr) * exp(-0.5 * (Mb + dL - m)^2/(merr^2))\n",
    "    bg_var = @. merr^2 + V\n",
    "    p_bg = @. 1. / sqrt(2. *pi*bg_var) * exp(-0.5 * (m - Y)^2/bg_var)\n",
    "    # Here, we weight the foreground probability by 1-pbad and the background by pbad,\n",
    "    # and then take the log.\n",
    "        lnl = sum(log.(\n",
    "            (1. .- pbad).*p_fg .+\n",
    "            pbad.*p_bg))\n",
    "    return lnl\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function fgbg_logprob(params)\n",
    "    Mb, Om, pbad, Y, V = params\n",
    "    return fgbg_line_log_likelihood(z, m, merr, Mb, Om, pbad, Y, V)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote a little function that allows me to find the maximum of a 2D array and the corresponding parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function find_max(A::Array{Float64, 2}, alo, ahi, alen, blo, bhi, blen)\n",
    "    store = [-Inf]\n",
    "    step1= (ahi-alo)/(alen-1)\n",
    "    step2= (bhi-blo)/(blen-1)\n",
    "    param1= [0]\n",
    "    param2=[0]\n",
    "    for i in 1:length(A[:,1])\n",
    "        for j in 1:length(A[1,:])\n",
    "            if(A[i,j] > store[1])\n",
    "                store = [A[i,j]]\n",
    "                param1= [alo+(j-1)*step1]\n",
    "                param2= [blo+(i-1)*step2]\n",
    "            elseif (A[i,j] == store[1])\n",
    "                push!(store, A[i,j])\n",
    "                push!(param1, alo+(j-1)*step1)\n",
    "                push!(param2, blo+(i-1)*step2)\n",
    "            end        \n",
    "        end\n",
    "    end\n",
    "    return store, param1, param2\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the log-likelihood is calculated. Also, using the function above, I return the best log-likelihood and the corresponding parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = mean(m);\n",
    "V = var(m);\n",
    "pbad = 0.1;\n",
    "Mblo,Mbhi = 19.5, 20.5\n",
    "Omlo,Omhi = .1, .9\n",
    "lMb, lOm = 401,501\n",
    "MbMb = range(Mblo, stop=Mbhi, length=lMb)\n",
    "OmOm = range(Omlo, stop=Omhi, length=lOm)\n",
    "LL = zeros((length(OmOm), length(MbMb)))\n",
    "for j in 1:length(MbMb)\n",
    "    for i in 1:length(OmOm)\n",
    "        LL[i,j] = fgbg_logprob((MbMb[j], OmOm[i], pbad, Y, V))\n",
    "    end\n",
    "end\n",
    "a,b,c = find_max(LL, Mblo, Mbhi, lMb, Omlo, Omhi, lOm)[1:3];\n",
    "best_val=a[1]\n",
    "best_Mb=b[1]\n",
    "best_Om=c[1]\n",
    "#best_Mb = find_max(LL, Mblo, Mbhi, lMb, Omlo, Omhi, lOm)[2][1];\n",
    "#best_Om = find_max(LL, Mblo, Mbhi, lMb, Omlo, Omhi, lOm)[3][1];\n",
    "println(\"Best logliklihood: \", best_val, \", best Mb: \", best_Mb, \" and best OmegaM: \", best_Om)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shift in the y-axis $M_b$ is very close to the estimated value above (offset = 20.061189941888113). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heatmap(LL, xlabel=\"Mb\", ylabel=\"OmegaM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heatmap(exp.(LL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The legend tells us that the range of the liklihoods is very big. This also can be seen by looking at the \"worst\" value of LL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worst_val = -find_max(-LL, Mblo, Mbhi, lMb, Omlo, Omhi, lOm)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To get a closer look at the \"interesting values above -100, I set all values smaller than -100 to -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL2 = copy(LL)\n",
    "for j in 1:length(LL2[1,:])\n",
    "    for i in 1:length(LL2[:,1])\n",
    "        if(LL2[i,j] < -100)\n",
    "            LL2[i,j] = -100\n",
    "        end\n",
    "    end\n",
    "end\n",
    "LL2[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heatmap(LL2, xlabel=\"Mb\", ylabel=\"OmegaM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the constraint in $\\Omega_M$ is more obvious, however it can be seen that it is not very strong. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(z, m, yerr=merr, seriestype=:scatter, label=\"\", xlabel=\"Redshift z\", ylabel=\"m\",\n",
    "title=\"Perlmutter+99 Supernovae\", legend=:bottomright)\n",
    "zgrid = 0.01:0.01:1.\n",
    "uni=LCDM(best_Om,1-best_Om,60.) #OmegaM = best_Om\n",
    "uni2=LCDM(0.75,0.25,60.) # OmegaM = 0.75\n",
    "uni3=LCDM(0.1,0.9,60.) # OmegaM = 0.25\n",
    "DL = map(z->distance_modulus(uni, z), zgrid)\n",
    "DL2 = map(z->distance_modulus(uni2, z), zgrid)\n",
    "DL3 = map(z->distance_modulus(uni3, z), zgrid)\n",
    "DLx2 = map(z->distance_modulus(uni2, z), z)\n",
    "offset2 = median(m - DLx2)\n",
    "DLx3 = map(z->distance_modulus(uni3, z), z)\n",
    "offset3 = median(m - DLx3)\n",
    "plot!(zgrid, DL .+ best_Mb, linewidth=3, label=\"Best Fit\")\n",
    "plot!(zgrid, DL2 .+ best_Mb, label=\"OmegaM = 0.75\")\n",
    "plot!(zgrid, DL3 .+ best_Mb, label=\"OmegaM = 0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that changing the values of $\\Omega_M$ (in range 0 to 1) from 0.1 to 0.75 has no drastic impact on the plot. This will be a problem for MCMC because the logliklihoods don't change a lot for small steps in $\\Omega_M$. \n",
    "\n",
    "When writing the run_mcmc function, I modified the function given in Lab3 so that there is another storage, that contains the parameters of each step and the corresponding logliklihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function run_mcmc(logprob_function, initial, jumpsizes, nsteps)\n",
    "    nparams = length(initial)\n",
    "    chain = zeros((nsteps, nparams))\n",
    "    results = zeros((nsteps, nparams+1))\n",
    "    logprobs = zeros(nsteps)\n",
    "    params = initial\n",
    "    logprob = logprob_function(params)\n",
    "    accepts = 0\n",
    "    for i in 1:nsteps\n",
    "        params_new = params .+ randn(nparams) .* jumpsizes\n",
    "        logprob_new = logprob_function(params_new)\n",
    "        if (exp(logprob_new - logprob) >= rand(Float64))\n",
    "            logprob = logprob_new\n",
    "            params = params_new\n",
    "            accepts += 1\n",
    "        end\n",
    "        chain[i,:] .= params\n",
    "        logprobs[i] = logprob\n",
    "        results[i,1:nparams] = chain[i,:]\n",
    "        results[i,end] = logprobs[i]\n",
    "    end\n",
    "    return logprobs, accepts / nsteps, results\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial = [19.5, .3, 0.1, mean(m), var(m)]\n",
    "jumpsizes = [.05, .01, 0.01, .5, 1.5]\n",
    "logprobs,acceptance, results = run_mcmc(fgbg_logprob, initial, jumpsizes, 2_000);\n",
    "acceptance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acceptance rate for these paramteres and jumpsizes seem reasonable, we always want to have a rate of approximately $50\\%$. Also the jumpsizes for the parameters make sense. We want to learn $\\Omega_M$ (second parameter) to an accuracy of two digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the chain leads to a similar picture like the heatmap of LL suggested. $M_b$ is stronlgy contraint around a region of 20 whereas $\\Omega_M$ fluctuates quite al lot roaround the best values. The reason for that is that the logprobabilities do not change strongly for small steps in $\\Omega_M$. Therefore  $exp(logprobnew-logprob)$ is close to 1 and steps away from the optimal values are very likely to be accepted. \n",
    "I modified the plot in a way that the color corresponds to the stored logliklihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(results[:,1], results[:,2], color=:black, label=\"\", xlabel=\"Mb\", ylabel=\"Omega\", legend=:bottomleft)\n",
    "scatter!(results[:,1], results[:,2], zcolor=results[:,end], ms=3, label=\"logprob\", colorbar=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one looks closely, the lightest area is around $\\Omega_M \\approx 0.33$ as the best_value/best_Om calculation already suggested. This value deviates from the values stated in the paper. As already stated, this might come from the fact that $\\Omega_M$ influences the fitted function in a logarithmic way. \n",
    "What usually is done that the first few chain elements are cut off. This is done in the following plot. I excluded the lines here because it gets really messy otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scatter(results[500:end,1], results[500:end,2], zcolor=results[500:end,end], ms=3, label=\"logprob\", \n",
    "        colorbar=true, legend=:bottomright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, the logliklihoods do not change a lot in the region from $\\Omega_M = 0.28 - 0.4$. The reason herefore is, as earlier stated, that this parameter influences the value of $m$ in a logarithmic way.\n",
    "Just out of curiosity, I searched the parameters that have the smallest logliklihood. The fit converges for these parameters the best, however slight deviations do not influence $\\chi^2$ strongly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max = maximum(results[:,end])\n",
    "for i in 1:length(results[:,end])\n",
    "    if results[i,end] == max\n",
    "        best_Mb_Markov, best_Om_Markov = results[i,1:2]\n",
    "        return best_Mb_Markov, best_Om_Markov, max, i\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
